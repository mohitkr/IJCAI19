> This paper considers learning an IP model (for satisfiability) from a
> collection of solutions and a language for specifying collection of
> constraints. The idea is to use tensors to describe subsets of constraints and
> reason via generalization to go from trivially true constraints to increasingly
> tight ones. Tensors are throw into 3 categories (Good/Bad/Ugly) to reflect
> their ability to tighten a formulation.
>
> The technique is applied to a small collection of classic CSPs where the
> objective is to assess the ability to construct a model that is a close as
> possible to the real things.
>
> I have a number of issues with the papers that should be addressed before it
> can be considered for publication. Namely:
>
> -- How does this scale to realistic problems and instances?

Mohit: we agree that the approaches scalability is limited to certain
complexity of the model. In the experiments section we chose the major
benchmark problems of Operations Research and the algorithm was able to learn
models with good precision and recall in realistic time, which shows that this
algorithm can be a good benchmark and could lead to some interesting follow up
works which make it more scalable

> -- Why is the work on constraint-miner not referenced, or compared to? This is
> the same purpose. How does it compare ?

Mohit: I am not sure which work this guy is talking about
Stefano: Nope.  We can simply say that we are not familiar with that work, and
we can compare to it if he gives us a reference.

> -- This is restricted to constraint satisfaction, so less capable then the
> constraint-miner.
>
> -- The empirical evidence provided failed to convince me whether the learned
> model is correct? (doesn't kill other solutions), related to the model a human
> would write? Readable? efficient?
>
> -- There is not nearly enough information in the paper to make an educated
> attempt at reproducing the results.
>
> I think that the authors must offer a compelling argument as to the value of
> learning models and the quality of the learned model. Prior work in the area
> cannot be overlooked, particularly when this is restricted to a specific
> sub-class that the prior art covers. I'm afraid this is not ready for prime
> time.
